{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "class BasePredictor:\n",
    "\n",
    "    def __init__(self, train_path: str, test_path: str):\n",
    "        self.train_dataset = pd.read_csv(train_path)\n",
    "        self.test_dataset = pd.read_csv(test_path)\n",
    "\n",
    "    def train(self) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, text: str) -> int:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def test(self):\n",
    "        correct_predictions = self.test_dataset['Author']\n",
    "        predictions = [\n",
    "            self.predict(row['Content'])\n",
    "            for _, row in self.test_dataset.iterrows()\n",
    "        ]\n",
    "        print(classification_report(correct_predictions, predictions))\n",
    "        print('F1-score:', f1_score(correct_predictions, predictions, average='macro'))\n",
    "        print(confusion_matrix(correct_predictions, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import zlib\n",
    "\n",
    "\n",
    "class ZipPredictor(BasePredictor):\n",
    "\n",
    "    def __init__(self, train_path: str, test_path: str):\n",
    "        super().__init__(train_path, test_path)\n",
    "        self.concatinated: dict[int, str] = defaultdict(str)\n",
    "\n",
    "    def _build_concatinated(self):\n",
    "        for _, row in self.train_dataset.iterrows():\n",
    "            self.concatinated[int(row['Author'])] += row['Content']\n",
    "\n",
    "    def train(self) -> int:\n",
    "        self._build_concatinated()\n",
    "\n",
    "    def predict(self, text: str) -> int:\n",
    "        compression = {}\n",
    "        for author_id, big_text in self.concatinated.items():\n",
    "            big_text_compression = len(zlib.compress((big_text).encode('utf-8'))) / len(big_text)\n",
    "            concat_text_compression = len(zlib.compress((big_text + text).encode('utf-8'))) / len(big_text + text)\n",
    "            compression_delta =  concat_text_compression - big_text_compression  # ищем, где качество сжатия ухудшилось меньше всего\n",
    "            compression[author_id] = compression_delta\n",
    "\n",
    "        return min(compression, key=lambda x: compression[x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       1.00      0.07      0.14        40\n",
      "           2       0.45      0.82      0.58        40\n",
      "           3       0.43      0.90      0.58        40\n",
      "\n",
      "    accuracy                           0.45       160\n",
      "   macro avg       0.47      0.45      0.33       160\n",
      "weighted avg       0.47      0.45      0.33       160\n",
      "\n",
      "F1-score: 0.3260627103678575\n",
      "[[ 0  0 23 17]\n",
      " [ 0  3 13 24]\n",
      " [ 0  0 33  7]\n",
      " [ 0  0  4 36]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "z = ZipPredictor('datasets/russian_classics/train_4_10_1000.csv', 'datasets/russian_classics/test_4_40_600.csv')\n",
    "z.train()\n",
    "z.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "class ThreeGramPredictor(BasePredictor):\n",
    "\n",
    "    def __init__(self, train_path: str, test_path: str):\n",
    "        super().__init__(train_path, test_path)\n",
    "        self.n_grams_idx = []\n",
    "        self.n_gram_vectors: dict[int, list[float]] = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str):\n",
    "        return ' '.join(re.findall(r'[a-zа-яё]+', text.lower()))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_n_grams(text: str):\n",
    "        text = ThreeGramPredictor.clean_text(text)\n",
    "        return [text[i:i + 3] for i in range(0, len(text) - 2)]\n",
    "\n",
    "    def vectorize(self, text) -> list[float]:\n",
    "        assert self.n_grams_idx\n",
    "\n",
    "        t_grams = self.get_n_grams(text)\n",
    "        counter = Counter(t_grams)\n",
    "        vector = [0] * len(self.n_grams_idx)\n",
    "        for t_gram, idx in self.n_grams_idx.items():\n",
    "            vector[idx] = counter.get(t_gram, 0)\n",
    "        total = sum(vector)\n",
    "        return [x / total for x in vector]\n",
    "\n",
    "    def train(self):\n",
    "        all_tgrams = self.get_n_grams(' '.join(row['Content'] for _, row in self.train_dataset.iterrows()))\n",
    "        self.n_grams_idx = {t_gram: idx for idx, t_gram in enumerate(set(all_tgrams))}\n",
    "\n",
    "        concatinated = defaultdict(str)\n",
    "        for _, row in self.train_dataset.iterrows():\n",
    "            concatinated[int(row['Author'])] += row['Content']\n",
    "\n",
    "        for author_id, text in concatinated.items():\n",
    "            self.n_gram_vectors[author_id] = self.vectorize(text)\n",
    "\n",
    "    @staticmethod\n",
    "    def cosine_distance(v1: list[float], v2: list[float]) -> float:\n",
    "        return sum((a - b) ** 2 for a, b in zip(v1, v2)) ** 0.5\n",
    "\n",
    "    def predict(self, text: str) -> int:\n",
    "        n_grams = self.get_n_grams(text)\n",
    "        counter = Counter(n_grams)\n",
    "        vector = [0] * len(self.n_grams_idx)\n",
    "        for tgram, idx in counter.items():\n",
    "            vector[idx] = counter[tgram]\n",
    "        total = sum(vector)\n",
    "        vector = [x / total for x in vector]\n",
    "\n",
    "        distances = {\n",
    "            author_id: self.cosine_distance(vector, author_vector)\n",
    "            for author_id, author_vector in self.n_gram_vectors.items()\n",
    "        }\n",
    "\n",
    "        return min(distances, key=lambda x: distances[x])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.33      0.12      0.18        40\n",
      "           2       0.24      0.88      0.38        40\n",
      "           3       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.25       160\n",
      "   macro avg       0.14      0.25      0.14       160\n",
      "weighted avg       0.14      0.25      0.14       160\n",
      "\n",
      "F1-score: 0.14056324110671936\n",
      "[[ 0  3 37  0]\n",
      " [ 1  5 34  0]\n",
      " [ 0  5 35  0]\n",
      " [ 0  2 38  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "t = ThreeGramPredictor('datasets/russian_classics/train_4_10_1000.csv', 'datasets/russian_classics/test_4_40_600.csv')\n",
    "t.train()\n",
    "t.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "class ThreeGramSVMPredictor(BasePredictor):\n",
    "\n",
    "    def __init__(self, train_path: str, test_path: str):\n",
    "        super().__init__(train_path, test_path)\n",
    "        self.n_grams_idx: dict[str, int] = {}\n",
    "        self.vectors: list[tuple[int, list[float]]] = []\n",
    "        self.model = SVC()\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str):\n",
    "        return ' '.join(re.findall(r'[a-zа-яё]+', text.lower()))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_n_grams(text: str):\n",
    "        text = ThreeGramPredictor.clean_text(text)\n",
    "        return [text[i:i + 3] for i in range(0, len(text) - 2)]\n",
    "\n",
    "    def vectorize(self, text) -> list[float]:\n",
    "        assert self.n_grams_idx\n",
    "\n",
    "        t_grams = self.get_n_grams(text)\n",
    "        counter = Counter(t_grams)\n",
    "        vector = [0] * len(self.n_grams_idx)\n",
    "        for t_gram, idx in self.n_grams_idx.items():\n",
    "            vector[idx] = counter.get(t_gram, 0)\n",
    "        total = sum(vector)\n",
    "        return [x / total for x in vector]\n",
    "\n",
    "    def train(self):\n",
    "        all_tgrams = self.get_n_grams(' '.join(row['Content'] for _, row in self.train_dataset.iterrows()))\n",
    "        self.n_grams_idx = {t_gram: idx for idx, t_gram in enumerate(set(all_tgrams))}\n",
    "\n",
    "        self.vectors = [\n",
    "            (row['Author'], self.vectorize(row['Content']))\n",
    "            for _, row in self.train_dataset.iterrows()\n",
    "        ]\n",
    "        self.model.fit([v for _, v in self.vectors], [a for a, _ in self.vectors])\n",
    "\n",
    "    def predict(self, text: str) -> int:\n",
    "        vector = self.vectorize(text)\n",
    "        return self.model.predict([vector])[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91        40\n",
      "           1       0.75      0.38      0.50        40\n",
      "           2       0.97      0.70      0.81        40\n",
      "           3       0.50      0.93      0.65        40\n",
      "\n",
      "    accuracy                           0.72       160\n",
      "   macro avg       0.79      0.72      0.72       160\n",
      "weighted avg       0.79      0.72      0.72       160\n",
      "\n",
      "F1-score: 0.7174519797517509\n",
      "[[35  2  0  3]\n",
      " [ 0 15  0 25]\n",
      " [ 2  1 28  9]\n",
      " [ 0  2  1 37]]\n"
     ]
    }
   ],
   "source": [
    "s = ThreeGramSVMPredictor('datasets/russian_classics/train_4_10_1000.csv', 'datasets/russian_classics/test_4_40_600.csv')\n",
    "s.train()\n",
    "s.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.88      0.57        26\n",
      "           1       0.33      0.25      0.29        40\n",
      "           2       0.40      0.53      0.46        40\n",
      "           3       0.21      0.89      0.34        35\n",
      "           4       1.00      0.20      0.33        40\n",
      "           5       0.71      0.25      0.37        40\n",
      "           6       0.47      0.50      0.48        40\n",
      "           7       0.28      0.20      0.23        40\n",
      "           8       0.78      0.53      0.63        40\n",
      "           9       1.00      0.10      0.18        40\n",
      "          10       0.73      0.88      0.80        40\n",
      "          11       0.39      0.61      0.48        36\n",
      "          12       0.91      0.72      0.81        40\n",
      "          13       1.00      0.07      0.14        40\n",
      "          14       0.96      0.55      0.70        40\n",
      "          15       0.41      0.93      0.57        40\n",
      "          16       0.64      0.40      0.49        40\n",
      "          17       1.00      0.03      0.05        40\n",
      "          18       0.26      0.15      0.19        40\n",
      "          19       0.66      0.68      0.67        40\n",
      "          20       0.00      0.00      0.00        22\n",
      "          21       0.29      0.60      0.39        40\n",
      "          22       0.77      0.75      0.76        40\n",
      "\n",
      "    accuracy                           0.46       879\n",
      "   macro avg       0.59      0.46      0.43       879\n",
      "weighted avg       0.61      0.46      0.44       879\n",
      "\n",
      "F1-score: 0.4309310373291422\n",
      "[[23  0  0  1  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 10  0 27  0  0  1  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0]\n",
      " [ 0  0 21  7  0  0  2  0  0  0  1  1  0  0  0  6  0  0  0  0  0  0  2]\n",
      " [ 0  1  0 31  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  1]\n",
      " [ 1  0  1  5  8  0  0  3  0  0  1  9  0  0  0  4  0  0  4  0  0  4  0]\n",
      " [ 0  0  2  1  0 10  1  5  0  0  1  4  0  0  0  0  0  0  1  7  4  4  0]\n",
      " [ 3  0  2  8  0  0 20  0  0  0  0  1  0  0  0  3  0  0  0  0  0  2  1]\n",
      " [ 9  0  2  3  0  0  0  8  0  0  0  2  0  0  0  0  1  0  7  4  0  4  0]\n",
      " [ 0  8  0  5  0  0  2  0 21  0  0  1  1  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  1  9 15  0  0  2  0  0  4  0  1  0  0  0  1  1  0  0  0  0  5  1]\n",
      " [ 0  3  0  0  0  0  0  0  0  0 35  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  1  0  0  0  1 22  0  0  0  9  0  0  1  0  0  1  0]\n",
      " [ 0  1  2  3  0  0  1  0  2  0  0  0 29  0  0  0  1  0  0  0  0  0  1]\n",
      " [ 4  1  1  1  0  0  1  0  1  0  0  3  0  3  0 13  3  0  0  1  1  4  3]\n",
      " [ 0  0  4 10  0  0  0  1  0  0  0  0  0  0 22  0  0  0  0  0  0  3  0]\n",
      " [ 0  0  0  1  0  0  1  0  0  0  1  0  0  0  0 37  0  0  0  0  0  0  0]\n",
      " [ 1  0  3  0  0  2  0  0  0  0  0  1  0  0  0  2 16  0  1  1  0 13  0]\n",
      " [ 7  0  1  8  0  0  9  0  0  0  0  5  0  0  0  4  0  1  1  0  0  4  0]\n",
      " [ 2  0  0  5  0  2  0  7  0  0  0  0  1  0  0  4  0  0  6  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  0  5  0  0  0  2  0  0  2 27  1  1  0]\n",
      " [ 1  3  3  0  0  0  0  3  2  0  8  0  1  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 4  1  1  7  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  1  0 24  0]\n",
      " [ 0  0  0  9  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 30]]\n"
     ]
    }
   ],
   "source": [
    "s = ThreeGramSVMPredictor('datasets/russian_classics/train_23_10_1000.csv', 'datasets/russian_classics/test_23_40_1000.csv')\n",
    "s.train()\n",
    "s.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class ThreeGramRandomForestPredictor(ThreeGramSVMPredictor):\n",
    "\n",
    "    def __init__(self, train_path: str, test_path: str):\n",
    "        super().__init__(train_path, test_path)\n",
    "        self.n_grams_idx: dict[str, int] = {}\n",
    "        self.vectors: list[tuple[int, list[float]]] = []\n",
    "        self.model = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_n_grams(text: str):\n",
    "        text = ThreeGramPredictor.clean_text(text)\n",
    "        return [text[i:i + 3] for i in range(0, len(text) - 2) if ' ' not in text[i:i + 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        40\n",
      "           1       0.78      1.00      0.88        40\n",
      "           2       0.85      0.72      0.78        40\n",
      "           3       0.82      0.68      0.74        40\n",
      "\n",
      "    accuracy                           0.81       160\n",
      "   macro avg       0.82      0.81      0.81       160\n",
      "weighted avg       0.82      0.81      0.81       160\n",
      "\n",
      "F1-score: 0.8079747457462124\n",
      "[[34  5  0  1]\n",
      " [ 0 40  0  0]\n",
      " [ 4  2 29  5]\n",
      " [ 4  4  5 27]]\n"
     ]
    }
   ],
   "source": [
    "r = ThreeGramRandomForestPredictor('datasets/russian_classics/train_4_10_1000.csv', 'datasets/russian_classics/test_4_40_600.csv')\n",
    "r.train()\n",
    "r.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.009309169086252834, 'еще'),\n",
       " (0.006896891781806129, 'тве'),\n",
       " (0.006330846492777131, 'душ'),\n",
       " (0.006167807824271111, 'енн'),\n",
       " (0.0059950175791715285, 'кот'),\n",
       " (0.005068994911029305, 'амо'),\n",
       " (0.0049584071307570135, 'льн'),\n",
       " (0.004804350383855186, 'год'),\n",
       " (0.0044800909024806, 'ств'),\n",
       " (0.004455937218906102, 'ьно'),\n",
       " (0.0044182431055065415, 'нно'),\n",
       " (0.004378168700792956, 'тво'),\n",
       " (0.00411100722433722, 'иди'),\n",
       " (0.003929786480019471, 'зак'),\n",
       " (0.0038859618964381913, 'вом'),\n",
       " (0.0038022256764205843, 'нте'),\n",
       " (0.0036937662830906727, 'ада'),\n",
       " (0.003678940799384179, 'всё'),\n",
       " (0.003651570600772305, 'лет'),\n",
       " (0.003638395937582947, 'тны'),\n",
       " (0.003573474930343697, 'ите'),\n",
       " (0.003496545783416789, 'одн'),\n",
       " (0.003476148470961268, 'ающ'),\n",
       " (0.003400099706462994, 'ени'),\n",
       " (0.003360963701971449, 'ани'),\n",
       " (0.003251519100712927, 'лек'),\n",
       " (0.0032242053359772256, 'дви'),\n",
       " (0.0031939444804709484, 'ещё'),\n",
       " (0.003129088042530563, 'вид'),\n",
       " (0.0031102803239466143, 'ата')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(zip(r.model.feature_importances_, list(r.n_grams_idx)), key=lambda x: -x[0]))[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.85      0.52        26\n",
      "           1       0.53      0.88      0.66        40\n",
      "           2       0.92      0.60      0.73        40\n",
      "           3       0.43      0.66      0.52        35\n",
      "           4       0.76      0.72      0.74        40\n",
      "           5       0.56      0.12      0.20        40\n",
      "           6       0.67      0.45      0.54        40\n",
      "           7       0.43      0.38      0.40        40\n",
      "           8       0.45      0.68      0.54        40\n",
      "           9       0.51      0.45      0.48        40\n",
      "          10       0.67      0.95      0.78        40\n",
      "          11       0.51      0.58      0.55        36\n",
      "          12       0.63      0.85      0.72        40\n",
      "          13       0.71      0.50      0.59        40\n",
      "          14       0.84      0.65      0.73        40\n",
      "          15       0.71      0.72      0.72        40\n",
      "          16       0.75      0.60      0.67        40\n",
      "          17       0.91      0.75      0.82        40\n",
      "          18       0.17      0.07      0.10        40\n",
      "          19       0.57      0.53      0.55        40\n",
      "          20       0.04      0.05      0.04        22\n",
      "          21       0.68      0.62      0.65        40\n",
      "          22       0.74      0.65      0.69        40\n",
      "\n",
      "    accuracy                           0.58       879\n",
      "   macro avg       0.59      0.58      0.56       879\n",
      "weighted avg       0.61      0.58      0.57       879\n",
      "\n",
      "F1-score: 0.5625224708802858\n",
      "[[22  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0 35  0  0  0  0  0  0  4  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0 24  1  3  0  0  0  0  2  1  1  0  3  0  2  0  0  0  2  0  0  1]\n",
      " [ 3  3  0 23  0  0  0  0  0  0  0  1  0  0  1  0  0  1  0  1  0  1  1]\n",
      " [ 2  0  0  0 29  1  0  1  0  0  0  2  0  0  0  1  0  0  2  0  0  0  2]\n",
      " [ 0  0  0  0  1  5  1  6  0  0  2  2  0  1  0  0  0  1  0  7 10  4  0]\n",
      " [ 2  3  0  0  0  0 18  0  2  1  0  0  4  1  2  0  5  0  0  1  0  0  1]\n",
      " [ 5  0  0  3  0  1  1 15  5  0  0  3  0  0  0  0  0  0  1  1  3  2  0]\n",
      " [ 0 12  0  0  0  0  1  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  1  5  0  0  1  0  8 18  0  0  0  0  0  0  1  0  0  1  3  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  1  2  1  0  3 21  0  0  0  4  0  1  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  0  0  0  1  3  0  0 34  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  1  0  1  1  1  1  3  2  2  0  2  0 20  1  0  0  0  0  0  2  0  1]\n",
      " [ 0  1  0  4  0  0  0  2  4  3  0  0  0  0 26  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  1  0  0  0  0  0  0  3  2  0  0  0 29  0  0  2  1  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0 24  0  0  0  0  0  0]\n",
      " [ 5  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0 30  0  1  1  0  1]\n",
      " [10  0  0  3  0  1  1  3  0  1  1  4  0  0  1  1  0  0  3  1  4  5  1]\n",
      " [ 1  0  0  0  0  0  0  1  0  0  0  1  0  1  0  4  0  0 10 21  1  0  0]\n",
      " [ 0  1  0  0  3  0  0  2  3  2  9  0  0  1  0  0  0  0  0  0  1  0  0]\n",
      " [ 5  2  0  3  0  0  0  0  1  2  0  2  0  0  0  0  0  0  0  0  0 25  0]\n",
      " [ 1  1  0  8  0  0  1  0  2  1  0  0  0  0  0  0  0  0  0  0  0  0 26]]\n"
     ]
    }
   ],
   "source": [
    "r = ThreeGramRandomForestPredictor('datasets/russian_classics/train_23_10_1000.csv', 'datasets/russian_classics/test_23_40_1000.csv')\n",
    "r.train()\n",
    "r.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy3\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "class WordsThreeGramsPredictor(BasePredictor):\n",
    "\n",
    "    def __init__(self, train_path: str, test_path: str):\n",
    "        super().__init__(train_path, test_path)\n",
    "        self.n_grams_idx: dict[str, int] = {}\n",
    "        self.vectors: list[tuple[int, list[float]]] = []\n",
    "        self.model = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> list[str]:\n",
    "        return [x for x in re.findall(r'[a-zа-яё]+|\\.|,|\\-|;|–|:', text.lower()) if x != ' ']\n",
    "\n",
    "    @staticmethod\n",
    "    def get_n_grams(text: str):\n",
    "        text = WordsThreeGramsPredictor.clean_text(text)\n",
    "\n",
    "        def preprocess(word):\n",
    "            if word in '+.,-;–:':\n",
    "                return word\n",
    "            return morph.parse(word)[0].tag.POS\n",
    "\n",
    "        grams = []\n",
    "        for i in range(0, len(text) - 2):\n",
    "            a, b, c = text[i:i + 3]\n",
    "            grams.append((preprocess(a), preprocess(b), preprocess(c)))\n",
    "\n",
    "        return grams\n",
    "\n",
    "    def vectorize(self, text) -> list[float]:\n",
    "        assert self.n_grams_idx\n",
    "\n",
    "        t_grams = self.get_n_grams(text)\n",
    "        counter = Counter(t_grams)\n",
    "        vector = [0] * len(self.n_grams_idx)\n",
    "        for t_gram, idx in self.n_grams_idx.items():\n",
    "            vector[idx] = counter.get(t_gram, 0)\n",
    "        total = sum(vector)\n",
    "        return [x / total for x in vector]\n",
    "\n",
    "    def train(self):\n",
    "        all_tgrams = self.get_n_grams(' '.join(row['Content'] for _, row in self.train_dataset.iterrows()))\n",
    "        self.n_grams_idx = {t_gram: idx for idx, t_gram in enumerate(set(all_tgrams))}\n",
    "\n",
    "        self.vectors = [\n",
    "            (row['Author'], self.vectorize(row['Content']))\n",
    "            for _, row in self.train_dataset.iterrows()\n",
    "        ]\n",
    "        self.model.fit([v for _, v in self.vectors], [a for a, _ in self.vectors])\n",
    "\n",
    "    def predict(self, text: str) -> int:\n",
    "        vector = self.vectorize(text)\n",
    "        return self.model.predict([vector])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80        40\n",
      "           1       0.80      0.90      0.85        40\n",
      "           2       0.85      0.70      0.77        40\n",
      "           3       0.78      0.78      0.78        40\n",
      "\n",
      "    accuracy                           0.80       160\n",
      "   macro avg       0.80      0.80      0.80       160\n",
      "weighted avg       0.80      0.80      0.80       160\n",
      "\n",
      "F1-score: 0.7985150399952831\n",
      "[[33  4  0  3]\n",
      " [ 0 36  3  1]\n",
      " [ 5  2 28  5]\n",
      " [ 4  3  2 31]]\n"
     ]
    }
   ],
   "source": [
    "w = WordsThreeGramsPredictor('datasets/russian_classics/train_4_10_1000.csv', 'datasets/russian_classics/test_4_40_600.csv')\n",
    "w.train()\n",
    "w.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.88      0.66        26\n",
      "           1       0.38      0.47      0.42        40\n",
      "           2       0.67      0.72      0.70        40\n",
      "           3       0.69      0.31      0.43        35\n",
      "           4       0.91      0.72      0.81        40\n",
      "           5       0.35      0.88      0.50        40\n",
      "           6       0.76      0.47      0.58        40\n",
      "           7       0.65      0.42      0.52        40\n",
      "           8       0.73      0.80      0.76        40\n",
      "           9       0.68      0.57      0.62        40\n",
      "          10       0.71      0.85      0.77        40\n",
      "          11       0.52      0.39      0.44        36\n",
      "          12       0.34      0.28      0.31        40\n",
      "          13       0.71      0.30      0.42        40\n",
      "          14       0.48      0.50      0.49        40\n",
      "          15       0.93      0.33      0.48        40\n",
      "          16       0.86      0.47      0.61        40\n",
      "          17       0.43      0.53      0.47        40\n",
      "          18       0.42      0.35      0.38        40\n",
      "          19       0.42      0.40      0.41        40\n",
      "          20       0.10      0.23      0.14        22\n",
      "          21       0.67      0.55      0.60        40\n",
      "          22       0.36      0.55      0.44        40\n",
      "\n",
      "    accuracy                           0.52       879\n",
      "   macro avg       0.58      0.52      0.52       879\n",
      "weighted avg       0.59      0.52      0.53       879\n",
      "\n",
      "F1-score: 0.5203379842609185\n",
      "[[23  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 1 19  1  0  0  0  0  0  2  9  0  0  1  0  5  0  0  0  0  0  0  0  2]\n",
      " [ 0  0 29  0  0  0  0  0  0  0  1  0  0  2  7  0  0  1  0  0  0  0  0]\n",
      " [ 2  0  2 11  1  3  1  0  1  0  0  1  0  0  0  0  0  1  1  0  2  0  9]\n",
      " [ 0  0  0  0 29  0  0  4  0  0  0  4  1  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  0 35  0  0  0  1  0  1  0  0  2  0  0  0  0  1  0  0  0]\n",
      " [ 1  0  0  0  0  3 19  0  0  0  0  0  0  0  1  0  0  0  2  0  6  0  8]\n",
      " [ 1  0  0  1  0 12  1 17  0  0  0  0  0  0  1  0  0  1  2  2  0  2  0]\n",
      " [ 0  4  0  0  0  0  0  0 32  0  0  0  3  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  4  0  0  0  2  0  0  1 23  0  0  0  0  0  0  2  3  0  0  0  0  5]\n",
      " [ 0  2  1  0  0  1  0  0  0  0 34  0  0  0  0  1  0  1  0  0  0  0  0]\n",
      " [ 3  0  2  0  2  0  0  0  0  0  3 14  2  1  0  0  0  0  7  0  0  2  0]\n",
      " [ 0  2  0  0  0  0  0  0  3  0  0  0 11  0  1  0  0  6  0  0  8  0  9]\n",
      " [ 2  1  1  1  0  7  0  0  1  1  0  1  0 12  2  0  0  9  0  0  1  1  0]\n",
      " [ 2  2  0  0  0  2  1  0  0  0  0  0  8  0 20  0  1  0  1  0  2  1  0]\n",
      " [ 0  0  1  0  0  3  0  0  0  0  2  5  0  1  0 13  0  2  0 13  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  3  0  0  0 19  0  0  0 14  0  3]\n",
      " [ 3  1  0  0  0  0  1  0  2  0  0  0  0  0  1  0  0 21  0  0 10  0  1]\n",
      " [ 5  0  0  2  0 10  0  1  0  0  1  0  1  0  0  0  0  1 14  1  0  4  0]\n",
      " [ 0  0  0  1  0 18  0  0  0  0  0  1  0  0  0  0  0  3  0 16  0  1  0]\n",
      " [ 0  2  1  0  0  0  0  4  0  0  7  0  0  1  1  0  0  0  0  0  5  0  1]\n",
      " [ 1  1  0  0  0  5  1  0  1  0  0  0  1  0  0  0  0  0  3  5  0 22  0]\n",
      " [ 0 11  5  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 22]]\n"
     ]
    }
   ],
   "source": [
    "w = WordsThreeGramsPredictor('datasets/russian_classics/train_23_10_1000.csv', 'datasets/russian_classics/test_23_40_1000.csv')\n",
    "w.train()\n",
    "w.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0033284187961860343, ('PREP', 'NOUN', '.')),\n",
       " (0.0031838514065482717, ('ADJF', 'NOUN', ';')),\n",
       " (0.0031719062214566516, ('VERB', 'NOUN', '.')),\n",
       " (0.0029930231966530108, (',', 'VERB', 'NPRO')),\n",
       " (0.002893573865672614, ('NOUN', ';', 'CONJ')),\n",
       " (0.002778986350330607, ('.', 'NOUN', 'VERB')),\n",
       " (0.0026163458471558185, ('ADJF', 'NOUN', ',')),\n",
       " (0.002571363046133408, ('ADJF', 'NOUN', '.')),\n",
       " (0.002554732247852976, ('VERB', '.', 'NOUN')),\n",
       " (0.002552396346602851, ('NOUN', '.', 'CONJ'))]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(zip(w.model.feature_importances_, list(w.n_grams_idx)), key=lambda x: -x[0]))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
