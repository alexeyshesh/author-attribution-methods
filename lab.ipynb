{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "class BasePredictor:\n",
    "\n",
    "    def __init__(self, train_path: str, test_path: str):\n",
    "        self.train_dataset = pd.read_csv(train_path)\n",
    "        self.test_dataset = pd.read_csv(test_path)\n",
    "\n",
    "    def train(self) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, text: str) -> int:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def test(self):\n",
    "        correct_predictions = self.test_dataset['Author']\n",
    "        predictions = [\n",
    "            self.predict(row['Content'])\n",
    "            for _, row in self.test_dataset.iterrows()\n",
    "        ]\n",
    "        print(classification_report(correct_predictions, predictions))\n",
    "        print('F1-score:', f1_score(correct_predictions, predictions, average='macro'))\n",
    "        print(confusion_matrix(correct_predictions, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import zlib\n",
    "\n",
    "\n",
    "class ZipPredictor(BasePredictor):\n",
    "\n",
    "    def __init__(self, train_path: str, test_path: str):\n",
    "        super().__init__(train_path, test_path)\n",
    "        self.concatinated: dict[int, str] = defaultdict(str)\n",
    "\n",
    "    def _build_concatinated(self):\n",
    "        for _, row in self.train_dataset.iterrows():\n",
    "            self.concatinated[int(row['Author'])] += row['Content']\n",
    "\n",
    "    def train(self) -> int:\n",
    "        self._build_concatinated()\n",
    "\n",
    "    def predict(self, text: str) -> int:\n",
    "        compression = {}\n",
    "        for author_id, big_text in self.concatinated.items():\n",
    "            big_text_compression = len(zlib.compress((big_text).encode('utf-8'))) / len(big_text)\n",
    "            concat_text_compression = len(zlib.compress((big_text + text).encode('utf-8'))) / len(big_text + text)\n",
    "            compression_delta =  concat_text_compression - big_text_compression  # ищем, где качество сжатия ухудшилось меньше всего\n",
    "            compression[author_id] = compression_delta\n",
    "\n",
    "        return min(compression, key=lambda x: compression[x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       1.00      0.07      0.14        40\n",
      "           2       0.45      0.82      0.58        40\n",
      "           3       0.43      0.90      0.58        40\n",
      "\n",
      "    accuracy                           0.45       160\n",
      "   macro avg       0.47      0.45      0.33       160\n",
      "weighted avg       0.47      0.45      0.33       160\n",
      "\n",
      "F1-score: 0.3260627103678575\n",
      "[[ 0  0 23 17]\n",
      " [ 0  3 13 24]\n",
      " [ 0  0 33  7]\n",
      " [ 0  0  4 36]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "z = ZipPredictor('datasets/russian_classics/train_4_10_1000.csv', 'datasets/russian_classics/test_4_40_600.csv')\n",
    "z.train()\n",
    "z.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "class ThreeGramPredictor(BasePredictor):\n",
    "\n",
    "    def __init__(self, train_path: str, test_path: str):\n",
    "        super().__init__(train_path, test_path)\n",
    "        self.n_grams_idx = []\n",
    "        self.n_gram_vectors: dict[int, list[float]] = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str):\n",
    "        return ' '.join(re.findall(r'[a-zа-яё]+', text.lower()))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_n_grams(text: str):\n",
    "        text = ThreeGramPredictor.clean_text(text)\n",
    "        return [text[i:i + 3] for i in range(0, len(text) - 2)]\n",
    "\n",
    "    def vectorize(self, text) -> list[float]:\n",
    "        assert self.n_grams_idx\n",
    "\n",
    "        t_grams = self.get_n_grams(text)\n",
    "        counter = Counter(t_grams)\n",
    "        vector = [0] * len(self.n_grams_idx)\n",
    "        for t_gram, idx in self.n_grams_idx.items():\n",
    "            vector[idx] = counter.get(t_gram, 0)\n",
    "        total = sum(vector)\n",
    "        return [x / total for x in vector]\n",
    "\n",
    "    def train(self):\n",
    "        all_tgrams = self.get_n_grams(' '.join(row['Content'] for _, row in self.train_dataset.iterrows()))\n",
    "        self.n_grams_idx = {t_gram: idx for idx, t_gram in enumerate(set(all_tgrams))}\n",
    "\n",
    "        concatinated = defaultdict(str)\n",
    "        for _, row in self.train_dataset.iterrows():\n",
    "            concatinated[int(row['Author'])] += row['Content']\n",
    "\n",
    "        for author_id, text in concatinated.items():\n",
    "            self.n_gram_vectors[author_id] = self.vectorize(text)\n",
    "\n",
    "    @staticmethod\n",
    "    def cosine_distance(v1: list[float], v2: list[float]) -> float:\n",
    "        return sum((a - b) ** 2 for a, b in zip(v1, v2)) ** 0.5\n",
    "\n",
    "    def predict(self, text: str) -> int:\n",
    "        n_grams = self.get_n_grams(text)\n",
    "        counter = Counter(n_grams)\n",
    "        vector = [0] * len(self.n_grams_idx)\n",
    "        for tgram, idx in counter.items():\n",
    "            vector[idx] = counter[tgram]\n",
    "        total = sum(vector)\n",
    "        vector = [x / total for x in vector]\n",
    "\n",
    "        distances = {\n",
    "            author_id: self.cosine_distance(vector, author_vector)\n",
    "            for author_id, author_vector in self.n_gram_vectors.items()\n",
    "        }\n",
    "\n",
    "        return min(distances, key=lambda x: distances[x])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.00      0.00      0.00        40\n",
      "           2       0.25      1.00      0.40        40\n",
      "           3       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.25       160\n",
      "   macro avg       0.06      0.25      0.10       160\n",
      "weighted avg       0.06      0.25      0.10       160\n",
      "\n",
      "F1-score: 0.1\n",
      "[[ 0  0 40  0]\n",
      " [ 0  0 40  0]\n",
      " [ 0  0 40  0]\n",
      " [ 0  0 40  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/alexeyshesh/author-attribution-methods/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "t = ThreeGramPredictor('datasets/russian_classics/train_4_10_1000.csv', 'datasets/russian_classics/test_4_40_600.csv')\n",
    "t.train()\n",
    "t.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "class ThreeGramSVMPredictor(BasePredictor):\n",
    "\n",
    "    def __init__(self, train_path: str, test_path: str):\n",
    "        super().__init__(train_path, test_path)\n",
    "        self.n_grams_idx: dict[str, int] = {}\n",
    "        self.vectors: list[tuple[int, list[float]]] = []\n",
    "        self.model = SVC()\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str):\n",
    "        return ' '.join(re.findall(r'[a-zа-яё]+', text.lower()))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_n_grams(text: str):\n",
    "        text = ThreeGramPredictor.clean_text(text)\n",
    "        return [text[i:i + 3] for i in range(0, len(text) - 2)]\n",
    "\n",
    "    def vectorize(self, text) -> list[float]:\n",
    "        assert self.n_grams_idx\n",
    "\n",
    "        t_grams = self.get_n_grams(text)\n",
    "        counter = Counter(t_grams)\n",
    "        vector = [0] * len(self.n_grams_idx)\n",
    "        for t_gram, idx in self.n_grams_idx.items():\n",
    "            vector[idx] = counter.get(t_gram, 0)\n",
    "        total = sum(vector)\n",
    "        return [x / total for x in vector]\n",
    "\n",
    "    def train(self):\n",
    "        all_tgrams = self.get_n_grams(' '.join(row['Content'] for _, row in self.train_dataset.iterrows()))\n",
    "        self.n_grams_idx = {t_gram: idx for idx, t_gram in enumerate(set(all_tgrams))}\n",
    "\n",
    "        self.vectors = [\n",
    "            (row['Author'], self.vectorize(row['Content']))\n",
    "            for _, row in self.train_dataset.iterrows()\n",
    "        ]\n",
    "        self.model.fit([v for _, v in self.vectors], [a for a, _ in self.vectors])\n",
    "\n",
    "    def predict(self, text: str) -> int:\n",
    "        vector = self.vectorize(text)\n",
    "        return self.model.predict([vector])[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91        40\n",
      "           1       0.75      0.38      0.50        40\n",
      "           2       0.97      0.70      0.81        40\n",
      "           3       0.50      0.93      0.65        40\n",
      "\n",
      "    accuracy                           0.72       160\n",
      "   macro avg       0.79      0.72      0.72       160\n",
      "weighted avg       0.79      0.72      0.72       160\n",
      "\n",
      "F1-score: 0.7174519797517509\n",
      "[[35  2  0  3]\n",
      " [ 0 15  0 25]\n",
      " [ 2  1 28  9]\n",
      " [ 0  2  1 37]]\n"
     ]
    }
   ],
   "source": [
    "s = ThreeGramSVMPredictor('datasets/russian_classics/train_4_10_1000.csv', 'datasets/russian_classics/test_4_40_600.csv')\n",
    "s.train()\n",
    "s.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.88      0.57        26\n",
      "           1       0.33      0.25      0.29        40\n",
      "           2       0.40      0.53      0.46        40\n",
      "           3       0.21      0.89      0.34        35\n",
      "           4       1.00      0.20      0.33        40\n",
      "           5       0.71      0.25      0.37        40\n",
      "           6       0.47      0.50      0.48        40\n",
      "           7       0.28      0.20      0.23        40\n",
      "           8       0.78      0.53      0.63        40\n",
      "           9       1.00      0.10      0.18        40\n",
      "          10       0.73      0.88      0.80        40\n",
      "          11       0.39      0.61      0.48        36\n",
      "          12       0.91      0.72      0.81        40\n",
      "          13       1.00      0.07      0.14        40\n",
      "          14       0.96      0.55      0.70        40\n",
      "          15       0.41      0.93      0.57        40\n",
      "          16       0.64      0.40      0.49        40\n",
      "          17       1.00      0.03      0.05        40\n",
      "          18       0.26      0.15      0.19        40\n",
      "          19       0.66      0.68      0.67        40\n",
      "          20       0.00      0.00      0.00        22\n",
      "          21       0.29      0.60      0.39        40\n",
      "          22       0.77      0.75      0.76        40\n",
      "\n",
      "    accuracy                           0.46       879\n",
      "   macro avg       0.59      0.46      0.43       879\n",
      "weighted avg       0.61      0.46      0.44       879\n",
      "\n",
      "F1-score: 0.4309310373291422\n",
      "[[23  0  0  1  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 10  0 27  0  0  1  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0]\n",
      " [ 0  0 21  7  0  0  2  0  0  0  1  1  0  0  0  6  0  0  0  0  0  0  2]\n",
      " [ 0  1  0 31  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  1]\n",
      " [ 1  0  1  5  8  0  0  3  0  0  1  9  0  0  0  4  0  0  4  0  0  4  0]\n",
      " [ 0  0  2  1  0 10  1  5  0  0  1  4  0  0  0  0  0  0  1  7  4  4  0]\n",
      " [ 3  0  2  8  0  0 20  0  0  0  0  1  0  0  0  3  0  0  0  0  0  2  1]\n",
      " [ 9  0  2  3  0  0  0  8  0  0  0  2  0  0  0  0  1  0  7  4  0  4  0]\n",
      " [ 0  8  0  5  0  0  2  0 21  0  0  1  1  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  1  9 15  0  0  2  0  0  4  0  1  0  0  0  1  1  0  0  0  0  5  1]\n",
      " [ 0  3  0  0  0  0  0  0  0  0 35  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  1  0  0  0  1 22  0  0  0  9  0  0  1  0  0  1  0]\n",
      " [ 0  1  2  3  0  0  1  0  2  0  0  0 29  0  0  0  1  0  0  0  0  0  1]\n",
      " [ 4  1  1  1  0  0  1  0  1  0  0  3  0  3  0 13  3  0  0  1  1  4  3]\n",
      " [ 0  0  4 10  0  0  0  1  0  0  0  0  0  0 22  0  0  0  0  0  0  3  0]\n",
      " [ 0  0  0  1  0  0  1  0  0  0  1  0  0  0  0 37  0  0  0  0  0  0  0]\n",
      " [ 1  0  3  0  0  2  0  0  0  0  0  1  0  0  0  2 16  0  1  1  0 13  0]\n",
      " [ 7  0  1  8  0  0  9  0  0  0  0  5  0  0  0  4  0  1  1  0  0  4  0]\n",
      " [ 2  0  0  5  0  2  0  7  0  0  0  0  1  0  0  4  0  0  6  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  0  5  0  0  0  2  0  0  2 27  1  1  0]\n",
      " [ 1  3  3  0  0  0  0  3  2  0  8  0  1  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 4  1  1  7  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  1  0 24  0]\n",
      " [ 0  0  0  9  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 30]]\n"
     ]
    }
   ],
   "source": [
    "s = ThreeGramSVMPredictor('datasets/russian_classics/train_23_10_1000.csv', 'datasets/russian_classics/test_23_40_1000.csv')\n",
    "s.train()\n",
    "s.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
